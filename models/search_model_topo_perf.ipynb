{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_helper as mh\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_toposearch(ds_split_seeds, dataset_folder, method, gnn_params, ds_name, results_path, gs_results):\n",
    "    epochs = 5000\n",
    "    results = {\n",
    "        'test_f1':None,\n",
    "        'test_auc':None,\n",
    "        'test_precision':None,\n",
    "        'test_recall':None,\n",
    "        'lr':None,\n",
    "        'w':None,\n",
    "        'K':None,\n",
    "        'F':None,\n",
    "        'K1':None,\n",
    "        'K2':None,\n",
    "        'F1':None,\n",
    "        'F2':None,\n",
    "        'epoch':None\n",
    "    }\n",
    "    best_model_diff = 1 #1 is worst\n",
    "    closest_f1 = 0\n",
    "    count = 1\n",
    "    for lr in gnn_params['lr']:\n",
    "        for w in gnn_params['w']:\n",
    "            if method == \"GINSAGE\":\n",
    "                \n",
    "                for K1 in gnn_params['K1']:\n",
    "                    for K2 in gnn_params['K2']:\n",
    "                        for F1 in gnn_params['F1']:\n",
    "                            for F2 in gnn_params['F2']:\n",
    "                                f1_scores_for_group = []\n",
    "                                best_epochs_for_group = []\n",
    "                                auc_scores_for_group = []\n",
    "                                precision_scores_for_group = []\n",
    "                                recall_scores_for_group = []\n",
    "                                seed_count = 0\n",
    "                                for seed in ds_split_seeds:\n",
    "                                    print(method, count, 'out of', len(gnn_params['lr'])*len(gnn_params['w'])*len(gnn_params['K1'])*len(gnn_params['K2'])*len(gnn_params['F1'])*len(gnn_params['F2'])*len(ds_split_seeds))\n",
    "                                    \n",
    "                                    ds = mh.Dataset()\n",
    "                                    ds.load_dataset(folder=dataset_folder+ds_name,splits=[0.5,0.2,0.3],split_type=\"normal\",split_seed=seed)\n",
    "                                    gin_feature_indices = [ds.feature_labels.index(item) for item in ['node_deg_out_unique', 'node_deg_in_unique']]\n",
    "                                    #gin_feature_indices = [ds.feature_labels.index(item) for item in ['node_deg_out', 'node_deg_in']]\n",
    "                                    #gin_feature_indices = [-1]\n",
    "                                    \n",
    "                                    model = mh.Model(ds.data, gridsearch_flag=True)\n",
    "                                    \n",
    "                                    additional_params = {'K1':K1, 'K2':K2, 'F1':F1, 'F2':F2, 'gin_feature_indices':gin_feature_indices}\n",
    "                                    model.w = w\n",
    "                                    model.lr = lr\n",
    "                                    model.load_model(\"GINSAGE\",additional_params=additional_params)\n",
    "                                    model.best_f1_from_gs = gnn_params['mean_f1']\n",
    "                                    #model.train_model(epochs=gnn_params['epochs'][seed_count])\n",
    "                                    model.train_model(epochs=5000)\n",
    "                                    f1_scores_for_group.append(model.gridsearch_results['test_f1'])\n",
    "                                    best_epochs_for_group.append(model.gridsearch_results['test_epoch'])\n",
    "                                    auc_scores_for_group.append(model.gridsearch_results['test_auc'])\n",
    "                                    precision_scores_for_group.append(model.gridsearch_results['test_precision'])\n",
    "                                    recall_scores_for_group.append(model.gridsearch_results['test_recall'])\n",
    "                                    count+=1\n",
    "                                    seed_count+=1\n",
    "                                '''\n",
    "                                if np.abs(model.gridsearch_results['test_f1'] - gnn_params['mean_f1']) < best_model_diff:\n",
    "                                    best_model_diff = np.abs(model.gridsearch_results['test_f1'] - gnn_params['mean_f1'])\n",
    "                                    closest_f1 = model.gridsearch_results['test_f1']\n",
    "                                    tpfp = model.check_topology_performance(folder=ds.folder, data=ds.data)\n",
    "                                    results = {\n",
    "                                    'tp':tpfp[0],\n",
    "                                    'fp':tpfp[1],\n",
    "                                    }\n",
    "                                '''\n",
    "                                '''\n",
    "                                for ele in results:\n",
    "                                    gs_results[ds_name][method][ele] = results[ele]\n",
    "                                    print(ele,results[ele])\n",
    "                                with open(results_path, 'w') as file:\n",
    "                                    json.dump(gs_results, file, indent=2)\n",
    "                                '''\n",
    "                                \n",
    "            else:\n",
    "                for K in gnn_params['K']:\n",
    "                    for F in gnn_params['F']:\n",
    "                        f1_scores_for_group = []\n",
    "                        best_epochs_for_group = []\n",
    "                        auc_scores_for_group = []\n",
    "                        precision_scores_for_group = []\n",
    "                        recall_scores_for_group = []\n",
    "                        seed_count = 0\n",
    "                        for seed in ds_split_seeds:\n",
    "                            print(method, count, 'out of', len(gnn_params['lr'])*len(gnn_params['w'])*len(gnn_params['K'])*len(gnn_params['F'])*len(ds_split_seeds))\n",
    "\n",
    "\n",
    "                            ds = mh.Dataset()\n",
    "                            ds.load_dataset(folder=dataset_folder+ds_name,splits=[0.5,0.2,0.3],split_type=\"normal\",split_seed=seed)\n",
    "\n",
    "                            model = mh.Model(ds.data, gridsearch_flag=True)\n",
    "                            model.w = w\n",
    "                            model.lr = lr\n",
    "                            model.load_model(method,K=K,F=F)\n",
    "                            model.best_f1_from_gs = gnn_params['mean_f1']\n",
    "                            #model.train_model(epochs=gnn_params['epochs'][seed_count])\n",
    "                            model.train_model(epochs=5000)\n",
    "                            f1_scores_for_group.append(model.gridsearch_results['test_f1'])\n",
    "                            best_epochs_for_group.append(model.gridsearch_results['test_epoch'])\n",
    "                            auc_scores_for_group.append(model.gridsearch_results['test_auc'])\n",
    "                            precision_scores_for_group.append(model.gridsearch_results['test_precision'])\n",
    "                            recall_scores_for_group.append(model.gridsearch_results['test_recall'])\n",
    "                            count+=1\n",
    "                            seed_count+=1\n",
    "                        '''\n",
    "                        if np.abs(model.gridsearch_results['test_f1'] - gnn_params['mean_f1']) < best_model_diff:\n",
    "                            best_model_diff = np.abs(model.gridsearch_results['test_f1'] - gnn_params['mean_f1'])\n",
    "                            closest_f1 = model.gridsearch_results['test_f1']\n",
    "                            tpfp = model.check_topology_performance(folder=ds.folder, data=ds.data)\n",
    "                            results = {\n",
    "                            'tp':tpfp[0],\n",
    "                            'fp':tpfp[1],\n",
    "                            }\n",
    "                        '''\n",
    "                        '''      \n",
    "                        for ele in results:\n",
    "                            gs_results[ds_name][method][ele] = results[ele]\n",
    "                            print(ele,results[ele])\n",
    "                        with open(results_path, 'w') as file:\n",
    "                            json.dump(gs_results, file, indent=2)\n",
    "                        '''       \n",
    "                        \n",
    "    #print(\"closest to mean f1:\",closest_f1)\n",
    "    #print(\"original median f1:\", gnn_params['mean_f1'])\n",
    "    #print(\"diff f1:\", np.abs(closest_f1-gnn_params['mean_f1']))\n",
    "    #print(\"results:\",results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_toposearch(ds,param_grid):\n",
    "    '''\n",
    "    param_grid = {'bootstrap': [True],\n",
    "        'max_depth': [70],\n",
    "        'max_features': ['sqrt'],\n",
    "        'min_samples_leaf': [4],\n",
    "        'min_samples_split': [5],\n",
    "        'n_estimators': [50]}\n",
    "    '''\n",
    "    trainX = ds.data.x[ds.data.train_mask + ds.data.val_mask].detach().cpu().numpy()\n",
    "    trainY = ds.data.y[ds.data.train_mask + ds.data.val_mask].detach().cpu().numpy()\n",
    "\n",
    "    testX = ds.data.x[ds.data.test_mask].detach().cpu().numpy()\n",
    "    testY = ds.data.y[ds.data.test_mask].detach().cpu().numpy()\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "    grid_search.fit(trainX, trainY)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    #clf = RandomForestClassifier(bootstrap=best_params['bootstrap'],max_depth=best_params['max_depth'],max_features=best_params['max_features'],min_samples_leaf=best_params['min_samples_leaf'],min_samples_split=best_params['min_samples_split'],n_estimators=best_params['n_estimators'])\n",
    "    #st = time.time()\n",
    "    #clf.fit(trainX, trainY)\n",
    "    #et = time.time()\n",
    "    #elapsed_time = et - st\n",
    "    #best_model = clf\n",
    "    \n",
    "    test_pred = best_model.predict(testX)\n",
    "    y_pred_prob = best_model.predict_proba(testX)\n",
    "    y_pred_prob = y_pred_prob[:,1]\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(testY, test_pred, average='binary')                     \n",
    "    fpr, tpr, thresholds = roc_curve(testY, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    #test_acc, test_out, test_pred = test(ds.data.test_mask,ds.data)\n",
    "    #test_pred = test_pred.detach().cpu()\n",
    "\n",
    "    test_pred = np.round(y_pred_prob)\n",
    "    y_true = ds.data.y[ds.data.test_mask].cpu()\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(ds.data.y[ds.data.test_mask].cpu(), test_pred, average='binary')\n",
    "    folder = \"v2/128K_05_v2_2\"\n",
    "    accounts_df = pd.read_csv(\"../datasets/\"+folder+\"/account_attributes.csv\")\n",
    "\n",
    "    indicies = accounts_df.index\n",
    "\n",
    "    out = np.array(test_pred)  # Convert 'out' to a NumPy array for easier indexing\n",
    "    true_labels = np.array(y_true)  # Convert 'true_labels' to a NumPy array for easier indexing\n",
    "\n",
    "    # True Positives (TP)\n",
    "    tp_indices = np.where((out == 1) & (true_labels == 1))[0]\n",
    "    print(\"true positives =\",len(tp_indices))\n",
    "    tp_indices = indicies[ds.data.test_mask.cpu().numpy()][tp_indices]\n",
    "\n",
    "    # True Negatives (TN)\n",
    "    tn_indices = np.where((out == 0) & (true_labels == 0))[0]\n",
    "    print(\"true negatives =\",len(tn_indices))\n",
    "    tn_indices = indicies[ds.data.test_mask.cpu().numpy()][tn_indices]\n",
    "\n",
    "    # False Positives (FP)\n",
    "    fp_indices = np.where((out == 1) & (true_labels == 0))[0]\n",
    "    print(\"false positives =\",len(fp_indices))\n",
    "    fp_indices = indicies[ds.data.test_mask.cpu().numpy()][fp_indices]\n",
    "\n",
    "    # False Negatives (FN)\n",
    "    fn_indices = np.where((out == 0) & (true_labels == 1))[0]\n",
    "    print(\"false negatives =\",len(fn_indices))\n",
    "    fn_indices = indicies[ds.data.test_mask.cpu().numpy()][fn_indices]\n",
    "\n",
    "    '''\n",
    "    accounts_df['trained_color'] = \"#000000\"\n",
    "    accounts_df['trained_color'][train_mask.numpy()] = \"#343B46\"\n",
    "    accounts_df['trained_color'][val_mask.numpy()] = \"#343B46\"\n",
    "    accounts_df['trained_color'][tp_indices] = \"#eb4034\"\n",
    "    accounts_df['trained_color'][tn_indices] = \"#1ad623\"\n",
    "    accounts_df['trained_color'][fp_indices] = \"#26e0be\"\n",
    "    accounts_df['trained_color'][fn_indices] = \"#fae01e\"\n",
    "    '''\n",
    "\n",
    "    accounts_df['trained_color'] = 1\n",
    "    accounts_df['trained_color'][ds.data.train_mask.cpu().numpy()] = 2\n",
    "    accounts_df['trained_color'][ds.data.val_mask.cpu().numpy()] = 2\n",
    "    accounts_df['trained_color'][tp_indices] = 3\n",
    "    accounts_df['trained_color'][tn_indices] = 4\n",
    "    accounts_df['trained_color'][fp_indices] = 5\n",
    "    accounts_df['trained_color'][fn_indices] = 6\n",
    "\n",
    "    #accounts_df['id'] = indicies\n",
    "    accounts_df['id'] = (accounts_df['id']).astype(int)\n",
    "\n",
    "    #accounts_df.to_csv('../datasets/60K_01_sar_count/account_attributes_trained_vis_SAGE.csv',index=0)\n",
    "\n",
    "    #np.sum(accounts_df['trained_color'] == 0), len(train_dataset), len(val_dataset), len(test_dataset)\n",
    "\n",
    "    sar_df = pd.read_csv(\"../datasets/\"+folder+\"/alert_accounts.csv\")\n",
    "\n",
    "    ids_cycle = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='cycle'].to_numpy() #super important to convert to numpy array!!!!! keeping as pandas series messes up all indexing!!!\n",
    "    ids_fan_in = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='fan_in'].to_numpy()\n",
    "    ids_fan_out = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='fan_out'].to_numpy()\n",
    "    ids_gather_scatter = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='gather_scatter'].to_numpy()\n",
    "    ids_scatter_gather = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='scatter_gather'].to_numpy()\n",
    "    ids_bipartite = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='bipartite'].to_numpy()\n",
    "    ids_stack = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='stack'].to_numpy()\n",
    "    set(sar_df[\"alert_type\"])\n",
    "\n",
    "    #print('ids_cycle',ids_cycle)\n",
    "\n",
    "    ids_test_set = accounts_df['id'][ds.data.test_mask.cpu().numpy()].astype(int).to_numpy()\n",
    "    labels_test_set = ds.data.y[ds.data.test_mask].cpu().numpy()\n",
    "    predictions_test_set = test_pred\n",
    "    correct_pos_pred = np.logical_and(labels_test_set, predictions_test_set) # is can only equal 1 if both label and precition were 1\n",
    "    print('correct_pos_pred',correct_pos_pred)\n",
    "    print(\"sanity check: num true positives, num total positives, sanity check, recall\")\n",
    "    print(np.sum(correct_pos_pred), np.sum(labels_test_set), np.round(np.sum(correct_pos_pred)/np.sum(labels_test_set),4), np.round(recall,4))\n",
    "    print(len(correct_pos_pred), len(ids_test_set),len(sar_df[\"acct_id\"]))\n",
    "    print(len(labels_test_set),len(predictions_test_set))\n",
    "\n",
    "    print(type(ids_test_set))\n",
    "\n",
    "    pred_cycle = correct_pos_pred[[e in ids_cycle for e in ids_test_set]]\n",
    "    pred_fan_in = correct_pos_pred[[e in ids_fan_in for e in ids_test_set]]\n",
    "    pred_fan_out = correct_pos_pred[[e in ids_fan_out for e in ids_test_set]]\n",
    "    pred_gather_scatter = correct_pos_pred[[e in ids_gather_scatter for e in ids_test_set]]\n",
    "    pred_scatter_gather = correct_pos_pred[[e in ids_scatter_gather for e in ids_test_set]]\n",
    "    pred_bipartite = correct_pos_pred[[e in ids_bipartite for e in ids_test_set]]\n",
    "    pred_stack = correct_pos_pred[[e in ids_stack for e in ids_test_set]]\n",
    "    print('pred cycle',pred_cycle)\n",
    "\n",
    "    #sanity check\n",
    "    print('sanity check')\n",
    "    print((len(pred_cycle) + len(pred_fan_in) + len(pred_fan_out) + len(pred_gather_scatter) + len(pred_scatter_gather)), np.sum(np.array(labels_test_set)), np.sum(np.array(correct_pos_pred)), len(correct_pos_pred))\n",
    "\n",
    "    topologies = ('Cycle', 'Fan In', 'Fan Out', 'Gather Scatter', 'Scatter Gather', 'Bipartite', 'Stack')\n",
    "\n",
    "    tp = np.round(np.array([np.sum(pred_cycle)/len(pred_cycle), np.sum(pred_fan_in)/len(pred_fan_in), np.sum(pred_fan_out)/len(pred_fan_out), np.sum(pred_gather_scatter)/len(pred_gather_scatter), np.sum(pred_scatter_gather)/len(pred_scatter_gather), np.sum(pred_bipartite)/len(pred_bipartite), np.sum(pred_stack)/len(pred_stack)]),2)\n",
    "    fp = np.ones(len(tp)) - tp\n",
    "    #print(tp)\n",
    "    topology_counts = {\n",
    "        'True Positive': tp,\n",
    "        'False Positive': fp,\n",
    "    }\n",
    "    print(f1_score)\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_toposearch(ds,params):\n",
    "    trainX = ds.data.x[ds.data.train_mask + ds.data.val_mask].detach().cpu().numpy()\n",
    "    trainY = ds.data.y[ds.data.train_mask + ds.data.val_mask].detach().cpu().numpy()\n",
    "\n",
    "    testX = ds.data.x[ds.data.test_mask].detach().cpu().numpy()\n",
    "    testY = ds.data.y[ds.data.test_mask].detach().cpu().numpy()\n",
    "\n",
    "    clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "    '''\n",
    "    params = {\n",
    "        \"gamma\": [0],\n",
    "        'max_depth': [30],\n",
    "        'n_estimators': [100]}\n",
    "    '''\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=params, cv=3, n_jobs=-1)\n",
    "    grid_search.fit(trainX, trainY)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    #clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42,gamma=best_params[\"gamma\"], max_depth=best_params[\"max_depth\"],n_estimators=best_params[\"n_estimators\"])\n",
    "    #st = time.time()\n",
    "    #clf.fit(trainX, trainY)\n",
    "    #et = time.time()\n",
    "    #elapsed_time = et - st\n",
    "\n",
    "    test_pred = best_model.predict(testX)\n",
    "    test_pred = np.round(test_pred)\n",
    "    print(np.sum(test_pred))\n",
    "\n",
    "    y_pred_prob = best_model.predict_proba(testX)\n",
    "    y_pred_prob = y_pred_prob[:,1]\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(testY, test_pred, average='binary')                     \n",
    "    fpr, tpr, thresholds = roc_curve(testY, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    #test_acc, test_out, test_pred = test(ds.data.test_mask,ds.data)\n",
    "    #test_pred = test_pred.detach().cpu()\n",
    "\n",
    "    test_pred = np.round(y_pred_prob)\n",
    "    y_true = ds.data.y[ds.data.test_mask].cpu()\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(ds.data.y[ds.data.test_mask].cpu(), test_pred, average='binary')\n",
    "    folder = \"v2/128K_05_v2_2\"\n",
    "    accounts_df = pd.read_csv(\"../datasets/\"+folder+\"/account_attributes.csv\")\n",
    "\n",
    "    indicies = accounts_df.index\n",
    "\n",
    "    out = np.array(test_pred)  # Convert 'out' to a NumPy array for easier indexing\n",
    "    true_labels = np.array(y_true)  # Convert 'true_labels' to a NumPy array for easier indexing\n",
    "\n",
    "    # True Positives (TP)\n",
    "    tp_indices = np.where((out == 1) & (true_labels == 1))[0]\n",
    "    print(\"true positives =\",len(tp_indices))\n",
    "    tp_indices = indicies[ds.data.test_mask.cpu().numpy()][tp_indices]\n",
    "\n",
    "    # True Negatives (TN)\n",
    "    tn_indices = np.where((out == 0) & (true_labels == 0))[0]\n",
    "    print(\"true negatives =\",len(tn_indices))\n",
    "    tn_indices = indicies[ds.data.test_mask.cpu().numpy()][tn_indices]\n",
    "\n",
    "    # False Positives (FP)\n",
    "    fp_indices = np.where((out == 1) & (true_labels == 0))[0]\n",
    "    print(\"false positives =\",len(fp_indices))\n",
    "    fp_indices = indicies[ds.data.test_mask.cpu().numpy()][fp_indices]\n",
    "\n",
    "    # False Negatives (FN)\n",
    "    fn_indices = np.where((out == 0) & (true_labels == 1))[0]\n",
    "    print(\"false negatives =\",len(fn_indices))\n",
    "    fn_indices = indicies[ds.data.test_mask.cpu().numpy()][fn_indices]\n",
    "\n",
    "    '''\n",
    "    accounts_df['trained_color'] = \"#000000\"\n",
    "    accounts_df['trained_color'][train_mask.numpy()] = \"#343B46\"\n",
    "    accounts_df['trained_color'][val_mask.numpy()] = \"#343B46\"\n",
    "    accounts_df['trained_color'][tp_indices] = \"#eb4034\"\n",
    "    accounts_df['trained_color'][tn_indices] = \"#1ad623\"\n",
    "    accounts_df['trained_color'][fp_indices] = \"#26e0be\"\n",
    "    accounts_df['trained_color'][fn_indices] = \"#fae01e\"\n",
    "    '''\n",
    "\n",
    "    accounts_df['trained_color'] = 1\n",
    "    accounts_df['trained_color'][ds.data.train_mask.cpu().numpy()] = 2\n",
    "    accounts_df['trained_color'][ds.data.val_mask.cpu().numpy()] = 2\n",
    "    accounts_df['trained_color'][tp_indices] = 3\n",
    "    accounts_df['trained_color'][tn_indices] = 4\n",
    "    accounts_df['trained_color'][fp_indices] = 5\n",
    "    accounts_df['trained_color'][fn_indices] = 6\n",
    "\n",
    "    #accounts_df['id'] = indicies\n",
    "    accounts_df['id'] = (accounts_df['id']).astype(int)\n",
    "\n",
    "    #accounts_df.to_csv('../datasets/60K_01_sar_count/account_attributes_trained_vis_SAGE.csv',index=0)\n",
    "\n",
    "    #np.sum(accounts_df['trained_color'] == 0), len(train_dataset), len(val_dataset), len(test_dataset)\n",
    "\n",
    "    sar_df = pd.read_csv(\"../datasets/\"+folder+\"/alert_accounts.csv\")\n",
    "\n",
    "    ids_cycle = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='cycle'].to_numpy() #super important to convert to numpy array!!!!! keeping as pandas series messes up all indexing!!!\n",
    "    ids_fan_in = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='fan_in'].to_numpy()\n",
    "    ids_fan_out = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='fan_out'].to_numpy()\n",
    "    ids_gather_scatter = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='gather_scatter'].to_numpy()\n",
    "    ids_scatter_gather = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='scatter_gather'].to_numpy()\n",
    "    ids_bipartite = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='bipartite'].to_numpy()\n",
    "    ids_stack = sar_df[\"acct_id\"][sar_df[\"alert_type\"]=='stack'].to_numpy()\n",
    "    set(sar_df[\"alert_type\"])\n",
    "\n",
    "    #print('ids_cycle',ids_cycle)\n",
    "\n",
    "    ids_test_set = accounts_df['id'][ds.data.test_mask.cpu().numpy()].astype(int).to_numpy()\n",
    "    labels_test_set = ds.data.y[ds.data.test_mask].cpu().numpy()\n",
    "    predictions_test_set = test_pred\n",
    "    correct_pos_pred = np.logical_and(labels_test_set, predictions_test_set) # is can only equal 1 if both label and precition were 1\n",
    "    print('correct_pos_pred',correct_pos_pred)\n",
    "    print(\"sanity check: num true positives, num total positives, sanity check, recall\")\n",
    "    print(np.sum(correct_pos_pred), np.sum(labels_test_set), np.round(np.sum(correct_pos_pred)/np.sum(labels_test_set),4), np.round(recall,4))\n",
    "    print(len(correct_pos_pred), len(ids_test_set),len(sar_df[\"acct_id\"]))\n",
    "    print(len(labels_test_set),len(predictions_test_set))\n",
    "\n",
    "    print(type(ids_test_set))\n",
    "\n",
    "    pred_cycle = correct_pos_pred[[e in ids_cycle for e in ids_test_set]]\n",
    "    pred_fan_in = correct_pos_pred[[e in ids_fan_in for e in ids_test_set]]\n",
    "    pred_fan_out = correct_pos_pred[[e in ids_fan_out for e in ids_test_set]]\n",
    "    pred_gather_scatter = correct_pos_pred[[e in ids_gather_scatter for e in ids_test_set]]\n",
    "    pred_scatter_gather = correct_pos_pred[[e in ids_scatter_gather for e in ids_test_set]]\n",
    "    pred_bipartite = correct_pos_pred[[e in ids_bipartite for e in ids_test_set]]\n",
    "    pred_stack = correct_pos_pred[[e in ids_stack for e in ids_test_set]]\n",
    "    print('pred cycle',pred_cycle)\n",
    "\n",
    "    #sanity check\n",
    "    print('sanity check')\n",
    "    print((len(pred_cycle) + len(pred_fan_in) + len(pred_fan_out) + len(pred_gather_scatter) + len(pred_scatter_gather)), np.sum(np.array(labels_test_set)), np.sum(np.array(correct_pos_pred)), len(correct_pos_pred))\n",
    "\n",
    "    topologies = ('Cycle', 'Fan In', 'Fan Out', 'Gather Scatter', 'Scatter Gather', 'Bipartite', 'Stack')\n",
    "\n",
    "    tp = np.round(np.array([np.sum(pred_cycle)/len(pred_cycle), np.sum(pred_fan_in)/len(pred_fan_in), np.sum(pred_fan_out)/len(pred_fan_out), np.sum(pred_gather_scatter)/len(pred_gather_scatter), np.sum(pred_scatter_gather)/len(pred_scatter_gather), np.sum(pred_bipartite)/len(pred_bipartite), np.sum(pred_stack)/len(pred_stack)]),2)\n",
    "    fp = np.ones(len(tp)) - tp\n",
    "    #print(tp)\n",
    "    topology_counts = {\n",
    "        'True Positive': tp,\n",
    "        'False Positive': fp,\n",
    "    }\n",
    "    print(f1_score)\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing JSON gridsearch results file loaded.\n",
      "device: cuda:0\n",
      "loading dataset v2/64K_5_v2 | length: 64026 | fraud percentage (%): 4.91\n",
      "Running Dataset 64K_5_v2\n",
      "    Running method XG\n",
      "seed 0\n",
      "device: cuda:0\n",
      "loading dataset v2/64K_5_v2 | length: 64026 | fraud percentage (%): 4.91\n",
      "682\n",
      "true positives = 660\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 128002 but corresponding boolean dimension is 64026",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 89\u001b[0m\n\u001b[0;32m     87\u001b[0m         ds \u001b[38;5;241m=\u001b[39m mh\u001b[38;5;241m.\u001b[39mDataset()\n\u001b[0;32m     88\u001b[0m         ds\u001b[38;5;241m.\u001b[39mload_dataset(folder\u001b[38;5;241m=\u001b[39mdataset_folder\u001b[38;5;241m+\u001b[39mds_name,splits\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.3\u001b[39m],split_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m,split_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m---> 89\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mxg_toposearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxg_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     91\u001b[0m     rf_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [gs_results[ds_name][method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [gs_results[ds_name][method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [gs_results[ds_name][method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [gs_results[ds_name][method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [gs_results[ds_name][method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [gs_results[ds_name][method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]]}\n",
      "Cell \u001b[1;32mIn[13], line 55\u001b[0m, in \u001b[0;36mxg_toposearch\u001b[1;34m(ds, params)\u001b[0m\n\u001b[0;32m     53\u001b[0m tp_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((out \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (true_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue positives =\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(tp_indices))\n\u001b[1;32m---> 55\u001b[0m tp_indices \u001b[38;5;241m=\u001b[39m \u001b[43mindicies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[tp_indices]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# True Negatives (TN)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m tn_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((out \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (true_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\anaconda\\envs\\anaconda\\envs\\GDL2\\lib\\site-packages\\pandas\\core\\indexes\\range.py:924\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(key):\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    919\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly integers, slices (`:`), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mellipsis (`...`), numpy.newaxis (`None`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand integer or boolean \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrays are valid indices\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    923\u001b[0m     )\n\u001b[1;32m--> 924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\anaconda\\envs\\GDL2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5195\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5192\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5193\u001b[0m         key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 5195\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 128002 but corresponding boolean dimension is 64026"
     ]
    }
   ],
   "source": [
    "#loop format\n",
    "#loop through datasets\n",
    "#loop through models\n",
    "#gridsearch model\n",
    "\n",
    "dataset_folder = 'v2/'\n",
    "#dataset_folder = 'thesis_datasets/'\n",
    "#datasets = ['128K_05_v2_2','128K_1_v2_2','128K_5_v2_2','128K_10_v2_2']\n",
    "#datasets = ['128K_5_v2_2','128K_10_v2_2','128K_1_v2_2','128K_05_v2_2']\n",
    "datasets = ['64K_5_v2']\n",
    "#datasets = ['128K_5_v2_2']\n",
    "methods = ['SAGE','XG','RF']\n",
    "methods = ['GINSAGE','SAGE','XG','RF']\n",
    "#methods = ['SAGE','GINSAGE']\n",
    "methods = ['XG','RF']\n",
    "#methods = ['RF','XG']\n",
    "\n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%Y-%m-%d\")\n",
    "current_time = now.strftime(\"%H-%M-%S\")\n",
    "result_string = f\"{current_date}_{current_time}\"\n",
    "\n",
    "results_path = 'gridsearch_results.json'\n",
    "#results_path = 'gridsearch_results/gridsearch_results_'+result_string+'.json'\n",
    "\n",
    "\n",
    "gs_results = {}\n",
    "try:\n",
    "    # Try to open the existing JSON file\n",
    "    with open(results_path, 'r') as file:\n",
    "        gs_results = json.load(file)\n",
    "        print(\"Existing JSON gridsearch results file loaded.\")\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist, create an empty dictionary\n",
    "    #gs_results = {}\n",
    "    print(\"JSON gridsearch results file not found\")\n",
    "    #with open(results_path, 'w') as file:\n",
    "    #    json.dump(gs_results, file, indent=2)\n",
    "\n",
    "for ds_name in datasets:\n",
    "\n",
    "    split_seeds = [0,111,222]\n",
    "    #split_seeds = [0,111,222,333,444,555,666,777,888,999]\n",
    "    #split_seeds = [0]\n",
    "    ds = mh.Dataset()\n",
    "    ds.load_dataset(folder=dataset_folder+ds_name,splits=[0.5,0.2,0.3],split_type=\"normal\")\n",
    "    print('Running Dataset',ds_name)\n",
    "\n",
    "    for method in methods:\n",
    "        model_path = './best_models/'+dataset_folder+ds_name+'_'+method+'.pth'\n",
    "        print('    Running method',method)\n",
    "       \n",
    "\n",
    "        \n",
    "        #gs_results[ds_name][method] = {}\n",
    "        \n",
    "        \n",
    "        results = {}\n",
    "        if method in ['GIN','SAGE','MPNN','GCN','GAT','GINSAGE']:\n",
    "            gnn_params = {\n",
    "                'lr':[gs_results[ds_name][method]['lr']],\n",
    "                'w':[gs_results[ds_name][method]['w']],\n",
    "                'K':[gs_results[ds_name][method]['K']],\n",
    "                'F':[gs_results[ds_name][method]['F']],\n",
    "                'K1':[gs_results[ds_name][method]['K1']],\n",
    "                'K2':[gs_results[ds_name][method]['K2']],\n",
    "                'F1':[gs_results[ds_name][method]['F1']],\n",
    "                'F2':[gs_results[ds_name][method]['F2']],\n",
    "                'mean_f1':gs_results[ds_name][method]['mean_f1'],\n",
    "                'epochs':gs_results[ds_name][method]['epoch']\n",
    "            }\n",
    "            model = mh.Model(ds.data, gridsearch_flag=True)\n",
    "            results = gnn_toposearch(split_seeds, dataset_folder, method, gnn_params, ds_name, results_path, gs_results)\n",
    "            '''\n",
    "            try:\n",
    "                results = gnn_gridsearch(model, ds, method, gnn_params)\n",
    "            except:\n",
    "                print(method,'on dataset',ds_name,'has crashed. Continuing to next seach.')\n",
    "            '''\n",
    "        elif method == 'XG':\n",
    "            xg_params = {\n",
    "                \"gamma\": [gs_results[ds_name][method]['gamma']],\n",
    "                'max_depth': [gs_results[ds_name][method]['max_depth']],\n",
    "                'n_estimators': [gs_results[ds_name][method]['n_estimators']]}\n",
    "            for seed in split_seeds:\n",
    "                print(\"seed\",seed)\n",
    "                ds = mh.Dataset()\n",
    "                ds.load_dataset(folder=dataset_folder+ds_name,splits=[0.5,0.2,0.3],split_type=\"normal\",split_seed=seed)\n",
    "                results = xg_toposearch(ds, xg_params)\n",
    "        elif method == 'RF':\n",
    "            rf_params = {'bootstrap': [gs_results[ds_name][method]['bootstrap']],\n",
    "                'max_depth': [gs_results[ds_name][method]['max_depth']],\n",
    "                'max_features': [gs_results[ds_name][method]['max_features']],\n",
    "                'min_samples_leaf': [gs_results[ds_name][method]['min_samples_leaf']],\n",
    "                'min_samples_split': [gs_results[ds_name][method]['min_samples_split']],\n",
    "                'n_estimators': [gs_results[ds_name][method]['n_estimators']]}\n",
    "            for seed in split_seeds:\n",
    "                print(\"seed\",seed)\n",
    "                ds = mh.Dataset()\n",
    "                ds.load_dataset(folder=dataset_folder+ds_name,splits=[0.5,0.2,0.3],split_type=\"normal\",split_seed=seed)\n",
    "                results = rf_toposearch(ds,rf_params)\n",
    "        else:\n",
    "            print('method',method,'does not exist!')\n",
    "        '''\n",
    "        for ele in results:\n",
    "            gs_results[ds_name][method][ele] = results[ele]\n",
    "            print(ele,results[ele])\n",
    "\n",
    "        with open(results_path, 'w') as file:\n",
    "            json.dump(gs_results, file, indent=2)\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
